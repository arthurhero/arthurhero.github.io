<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching">
  <meta property="og:title" content="PointRecon"/>
  <meta property="og:description" content="Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching"/>
  <meta property="og:url" content="https://arthurhero.github.io/projects/pointrecon/index.html"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/fig1_crop.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="PointRecon">
  <meta name="twitter:description" content="Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/fig1_crop.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="3D Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>PointRecon</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script>
    $(function(){
      $("#DivContent").load("videos.html");
    });
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><a href="https://chenziwe.com/" target="_blank">Ziwen Chen</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://zexiangxu.github.io/" target="_blank">Zexiang Xu</a><sup>2</sup>,</span>
              <class="author-block"><a href="https://web.engr.oregonstate.edu/~lif/" target="_blank">Fuxin Li</a><sup>1</sup></span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="eql-cntrb"><br><sup>1</sup>Oregon State University</span>
              <span class="eql-cntrb"><sup>2</sup>Adobe Research</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                  <a href="https://arxiv.org/abs/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
        </div>
        </div>

        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose a novel online, point-based 3D reconstruction method from posed monocular RGB videos. 
            Our model maintains a global point cloud representation of the scene, continuously updating the 
            features and 3D locations of points as new images are observed. It expands the point cloud with 
            newly detected points while carefully removing redundancies. The point cloud updates and depth 
            predictions for new points are achieved through a novel ray-based 2D-3D feature matching technique, 
            which is robust against errors in previous point position predictions. In contrast to offline methods, 
            our approach processes infinite-length sequences and provides real-time updates. Additionally, 
            the point cloud imposes no pre-defined resolution or scene size constraints, and its unified global 
            representation ensures view consistency across perspectives. Experiments on the ScanNet dataset show 
            that our method achieves state-of-the-art quality among online MVS approaches.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop" style="text-align:center;">
    <div class="hero-body">
      <img src="static/images/fig1_crop.jpg" style="margin: 30px;" width="800" height="400">
      Workflow of PointRecon. We begin with monocular depth prediction for the first image, 
      lifting 2D points into 3D space to form the initial point cloud. For each subsequent image, 
      we perform feature matching between the 2D image features and the 3D point cloud features to 
      update the features and positions of the point cloud and to predict depth for the 2D image. 
      Finally, the new points are merged with the existing point cloud. 
      <br><br>
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="https://huggingface.co/arthurhero/pointrecon_stuff/resolve/main/videos/scene0708_00.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- Recon video-->
<section class="hero is-small is-light" id="recon">
  <div class="hero-body">
  <div class="container is-centered is-max-desktop" style="text-align:center;">
    <h2 class="title">More Scannet Reconstruction Videos</h2>
    <p>ul: input image, ur: rendered depth<br>
       ll: first-person view reconstruction, lr: birdeye-view reconstruction</p>
       <br><br>

       <div id="DivContent"></div>

  </div>
  </div>
</section>
<!-- End recon video -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ziwen2024llrm,
title={PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching},
author={Ziwen, Chen and Xu, Zexiang and Fuxin, Li},
journal={arXiv preprint },
year={2024}
}</code></pre>
  </div>
</section>

 <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>